{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10615239,"sourceType":"datasetVersion","datasetId":6572021},{"sourceId":10630384,"sourceType":"datasetVersion","datasetId":6581909},{"sourceId":10630565,"sourceType":"datasetVersion","datasetId":6581986},{"sourceId":10632104,"sourceType":"datasetVersion","datasetId":6582621}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas numpy matplotlib seaborn scikit-learn xgboost lightgbm catboost imbalanced-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T04:22:17.709374Z","iopub.execute_input":"2025-02-01T04:22:17.709940Z","iopub.status.idle":"2025-02-01T04:22:22.880658Z","shell.execute_reply.started":"2025-02-01T04:22:17.709898Z","shell.execute_reply":"2025-02-01T04:22:22.878883Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.1)\nRequirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\nRequirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.5.0)\nRequirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.7)\nRequirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\nRequirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"import joblib\nimport pandas as pd\nimport numpy as np\n\n# Load required libraries for predictions\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-01T04:22:22.882992Z","iopub.execute_input":"2025-02-01T04:22:22.883630Z","iopub.status.idle":"2025-02-01T04:22:22.891479Z","shell.execute_reply.started":"2025-02-01T04:22:22.883576Z","shell.execute_reply":"2025-02-01T04:22:22.890018Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"import joblib\nimport pandas as pd\nimport numpy as np\n\n# === Load the saved scaler ===\nscaler_pe = joblib.load('/kaggle/input/scalers/scaler_pe.pkl')  \n\n# === Load the saved ensemble models ===\nensemble_models_pe = joblib.load('/kaggle/input/dependencies/ensemble_model_pe.pkl')\n\n# === Extract individual models from the ensemble ===\nbest_xgb_pe = ensemble_models_pe['best_xgb']\nbest_lgbm_pe = ensemble_models_pe['best_lgbm']\nmeta_model_pe = ensemble_models_pe['meta_model']\n\nprint(\"Models and scaler loaded successfully!\")\n\n# === Load the PE test data ===\ntest_data_pe = pd.read_csv(\"/kaggle/input/crest-dataset/dataset/test.csv\")  # Replace with the actual test file path\n\n# === Load selected features ===\nselected_features_pe = pd.read_csv(\"/kaggle/input/dependencies/selected_features_pe.csv\", header=None)\nselected_features_pe = selected_features_pe.iloc[1:][0].tolist()  # Remove header row if necessary\n\n# === Select only relevant columns based on training data features ===\ntest_selected_features_pe = test_data_pe[selected_features_pe]\n\n# === Apply log transformation & handle NaN values ===\ntest_selected_features_pe = np.log1p(test_selected_features_pe)  \ntest_selected_features_pe = np.nan_to_num(test_selected_features_pe)\n\n# === Apply the loaded scaler ===\ntest_scaled_pe = scaler_pe.transform(test_selected_features_pe)\n\nprint(\"Test data preprocessed successfully!\")\n\n# === Get probabilities from base models (XGBoost and LightGBM) ===\nxgb_probs_pe = best_xgb_pe.predict_proba(test_scaled_pe)  # Get probabilities from XGBoost\nlgbm_probs_pe = best_lgbm_pe.predict_proba(test_scaled_pe)  # Get probabilities from LightGBM\n\n# === Create metadata for Meta-Model ===\nmetadata_df_pe = pd.DataFrame(xgb_probs_pe, columns=[f\"xgb_class_{i}\" for i in range(xgb_probs_pe.shape[1])])\nmetadata_df_pe = metadata_df_pe.join(pd.DataFrame(lgbm_probs_pe, columns=[f\"lgbm_class_{i}\" for i in range(lgbm_probs_pe.shape[1])]))\n\n# === Check if the meta-model is expecting the correct number of features ===\nprint(\"Metadata shape:\", metadata_df_pe.shape)  # This should match the expected number of features in the meta-model\n\n# === Predict final probabilities using Meta-Model ===\nfinal_probs_pe = meta_model_pe.predict_proba(metadata_df_pe)  # Get final probabilities from meta-model\n\n# === Convert probabilities to final class predictions ===\nfinal_predictions_pe = np.argmax(final_probs_pe, axis=1)  # Convert to final class predictions by taking the max probability\n\n# === Prepare and save the final predictions ===\nfinal_predictions_df = pd.DataFrame({\n    \"SHA256\": test_data_pe[\"SHA256\"],  # Include SHA256 for traceability\n    \"Final_Predicted_Class\": final_predictions_pe\n})\n\n# Save the final predictions\nfinal_predictions_df.to_csv(\"final_predictions_pe.csv\", index=False)\nprint(\"Predictions generated and saved to 'final_predictions_pe.csv'!\")\n\n# === Save the metadata for future use ===\nmetadata_df_pe.to_csv(\"metadata_pe.csv\", index=False)\nprint(\"Metadata saved to 'metadata_pe.csv' for meta-model training!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T04:22:33.179462Z","iopub.execute_input":"2025-02-01T04:22:33.179807Z","iopub.status.idle":"2025-02-01T04:22:43.230973Z","shell.execute_reply.started":"2025-02-01T04:22:33.179779Z","shell.execute_reply":"2025-02-01T04:22:43.229457Z"}},"outputs":[{"name":"stdout","text":"Models and scaler loaded successfully!\nTest data preprocessed successfully!\nMetadata shape: (1480, 14)\nPredictions generated and saved to 'final_predictions_pe.csv'!\nMetadata saved to 'metadata_pe.csv' for meta-model training!\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n  class attribute, which is a dictionary `param_name: list of constraints`. See\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# === Load the test metadata (PE in this case) ===\nmetadata_pe_test = pd.read_csv(\"/kaggle/working/metadata_pe.csv\")  # PE metadata for test\n\n# === Load the saved meta-model (already trained) ===\nmeta_model = meta_model_pe\n\n# === Get predictions using the meta-model ===\nfinal_predictions_test = meta_model.predict(metadata_pe_test)\n\n# === Get class probabilities (in case you want to do argmax on them) ===\n# If you're using probabilities for final predictions (if required)\n# final_predictions_prob = meta_model.predict_proba(metadata_pe_test)\n\n# === Prepare the final output (SHA256 and label) ===\ntest_data = pd.read_csv(\"/kaggle/input/crest-dataset/dataset/test.csv\")  # Assuming original test data is available for SHA256\ntest_submit = pd.DataFrame({\n    \"SHA256\": test_data[\"SHA256\"],  # Use the SHA256 column from the original test data\n    \"label\": final_predictions_test  # Use the predicted labels from the meta-model\n})\n\n# === Save the predictions to test_submit.csv ===\ntest_submit.to_csv(\"/kaggle/working/test_submit.csv\", index=False)\nprint(\"Submission file 'test_submit.csv' created successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T05:38:30.038171Z","iopub.execute_input":"2025-02-01T05:38:30.038914Z","iopub.status.idle":"2025-02-01T05:38:40.102479Z","shell.execute_reply.started":"2025-02-01T05:38:30.038857Z","shell.execute_reply":"2025-02-01T05:38:40.101183Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n  class attribute, which is a dictionary `param_name: list of constraints`. See\n","output_type":"stream"},{"name":"stdout","text":"Submission file 'test_submit.csv' created successfully!\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T05:34:35.865512Z","iopub.execute_input":"2025-02-01T05:34:35.865978Z","iopub.status.idle":"2025-02-01T05:34:35.897867Z","shell.execute_reply.started":"2025-02-01T05:34:35.865947Z","shell.execute_reply":"2025-02-01T05:34:35.896159Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-56-3f42e6aaa4e2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStackingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEnsemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_forest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_forest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_forest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomTreesEmbedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEnsemble\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_partition_estimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name '_joblib_parallel_args' from 'sklearn.utils.fixes' (/usr/local/lib/python3.10/dist-packages/sklearn/utils/fixes.py)"],"ename":"ImportError","evalue":"cannot import name '_joblib_parallel_args' from 'sklearn.utils.fixes' (/usr/local/lib/python3.10/dist-packages/sklearn/utils/fixes.py)","output_type":"error"}],"execution_count":56},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}